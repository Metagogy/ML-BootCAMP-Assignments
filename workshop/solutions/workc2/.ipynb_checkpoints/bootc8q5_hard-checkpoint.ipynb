{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Load, Split, normalize and flatten the mnist dataset. Build, compile, train and evaluate the model using adam optimizer, loss as \"categorical_crossentropy\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description :** \n",
    "\n",
    "* Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
    "\n",
    "* Normalize the dataset images by dividing it with 255 and subtract 0.5 of train and test images. \n",
    "\n",
    "* Flatten the dataset images by using reshape. \n",
    "\n",
    "* Build the mnist dataset model by using a sequential layer and adding first two activation functions as Relu layers having 64 neurons in each dense layer and last layer having activation function as Softmax layer with 10 neurons.\n",
    "\n",
    "* Compile the model using adam optimizer, loss as \"categorical_crossentropy\" and train the model using 5 epochs, 32 as batch size.\n",
    "\n",
    "* Evaluate the mnist model by using test images and labels. Print the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level :** Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format :** \n",
    "\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format :**\n",
    "\n",
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample input :** \n",
    "\n",
    "Load the dataset using inbuilt function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output  :**\n",
    "\n",
    "Accuracy : 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries.\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into train and test.\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels =   tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu' , input_shape=(784, )))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu' ))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy() ,optimizer= 'sgd', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6716 - accuracy: 0.8170\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3298 - accuracy: 0.9040\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2831 - accuracy: 0.9174\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2485 - accuracy: 0.9271\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2205 - accuracy: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8791b6f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model.\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=10,\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.2044 - accuracy: 0.9393\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "loss,acc=model.evaluate(\n",
    "  test_images,\n",
    "  test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939300000667572\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy.\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
