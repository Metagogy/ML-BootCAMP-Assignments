{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Load, Split, normalize and flatten the mnist dataset. Build, compile, train and evaluate the model using adam optimizer, loss as \"categorical_crossentropy\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description :** \n",
    "\n",
    "* Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
    "\n",
    "* Normalize the dataset images by dividing it with 255 and subtract 0.5 of train and test images. \n",
    "\n",
    "* Flatten the dataset images by using reshape. \n",
    "\n",
    "* Convert train and test labels to binary class matrix with the help of to_categorical\n",
    "\n",
    "* Build the mnist dataset model by using a sequential layer and adding first two activation functions as Relu layers having 64 neurons in each dense layer and last layer having activation function as Softmax layer with 10 neurons.\n",
    "\n",
    "* Compile the model using sgd optimizer, loss as \"categorical_crossentropy\" and train the model using 10 epochs, 32 as batch size.\n",
    "\n",
    "* Evaluate the mnist model by using test images and labels. Print the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level :** Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format :** \n",
    "\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format :**\n",
    "\n",
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample input :** \n",
    "\n",
    "Load the dataset using inbuilt function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output  :**\n",
    "\n",
    "Accuracy : 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries.\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into train and test.\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels =   tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu' , input_shape=(784, )))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu' ))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy() ,optimizer= 'sgd', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6897 - accuracy: 0.8066\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3309 - accuracy: 0.9026\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2810 - accuracy: 0.9183\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2494 - accuracy: 0.9270\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2240 - accuracy: 0.9345\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2028 - accuracy: 0.9409\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1859 - accuracy: 0.9456\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1720 - accuracy: 0.9501\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1607 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1508 - accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47a8cc9730>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model.\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=10,\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1658 - accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "loss,acc=model.evaluate(\n",
    "  test_images,\n",
    "  test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9491999745368958\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy.\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
