{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Build, compile, train the sunspot dataset using the LSTM model with callbacks, dropouts and print the mean absolute error loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Description**:\n",
    "\n",
    "* The dataset consists from 1749/01/01 to 2017/08/31 \n",
    "\n",
    "* Load the dataset using pandas \n",
    "\n",
    "* Split the dataset into training till 3000 rows and testing sets as remaining \n",
    "\n",
    "* By using helper function turn data into a window dataset\n",
    "\n",
    "* For inference, we just need to convert the data into multiple samples of predictor variables.\n",
    "\n",
    "* For input, we are converting the time series into samples of 60 (window_size). The first 59 data points of a sample will be used as the predictor variables while the last data point will be used as the target variable.\n",
    "\n",
    "* Build a sequential model where input layer is Conv1D with 60 filters, kernel size as 5, relu as activation. Add 2 layers of lstm layers with 60 neurons each. Add two dense layers where 30 and 10 neurons respectively. Use dropout as 0.5. Finally, add lambda layer for scaling output to same range of values\n",
    "\n",
    "* Use LearningRateScheduler as callback\n",
    "\n",
    "* Compile the model using Huber as loss, ‘mae’ as an optimizer, learning rate as 1e-5\n",
    "\n",
    "* Train the model using 15 epochs and batch size as 32\n",
    "\n",
    "* Display the absolute mean error loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Your Code From Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset.\n",
    "\n",
    "df = # Complete Your Code Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.array(list(df.index))\n",
    "sunspots = list(df['Monthly Mean Total Sunspot Number'])\n",
    "series = np.array(sunspots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test data.\n",
    "\n",
    "t_train = # Complete Your Code Here.\n",
    "train = # Complete Your Code Here.\n",
    "t_test = # Complete Your Code Here.\n",
    "test = # Complete Your Code Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60  \n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "forecast_period = 30  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowed_dataset function.\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)  \n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda i: i.batch(window_size))\n",
    "    s = s.map(lambda i: (i[:-1], i[-1:]))  \n",
    "    s = s.shuffle(shuffle_buffer)  \n",
    "    s = s.batch(batch_size).prefetch(1) \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_forecast function.\n",
    "\n",
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda w: w.batch(window_size))\n",
    "    s = s.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(s)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = windowed_dataset(train, window_size=window_size,batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build  model.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(# Complete Your Code Here.), \n",
    "  tf.keras.layers.LSTM(# Complete Your Code Here. ),\n",
    "  tf.keras.layers.LSTM(# Complete Your Code Here. ),\n",
    "  tf.keras.layers.Dense(# Complete Your Code Here. ),\n",
    "  tf.keras.layers.Dense(# Complete Your Code Here. ),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(# Complete Your Code Here. ),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-5 * 10**(epoch / 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "\n",
    "result = model.fit(# Complete Your Code Here.,\n",
    "                   verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model_forecast(model,series[..., np.newaxis],window_size, batch_size)[3000 - window_size + 1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = tf.keras.metrics.mean_absolute_error(# Complete Your Code Here. ).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean absolute error.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
