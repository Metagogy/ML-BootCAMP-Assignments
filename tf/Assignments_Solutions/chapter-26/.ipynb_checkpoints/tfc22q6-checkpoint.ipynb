{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Apply word2vec on a given paragraph, and print the most similar words for a word given as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** : \n",
    "\n",
    "Import necessary libraries \n",
    "\n",
    "Preprocess the paragraph by using regular expressions ( it removes special characters like number , commas , etc.  next apply sentence tokenizer for given paragraph then next word_tokenize. In the next step remove stop words( it removes a, an , the etc. ) and any punctuations(like !@#$%^&*()\"''``:;.,)\n",
    "\n",
    "Apply word2vec for given paragraph and use min_count = 1 ( Here we are using min count = 1 because our input data is less so we are using 1 if our data is huge then we will use 2 or 3 )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** : String."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format** : List of similar words in a paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input** : \n",
    "\n",
    "portions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** :\n",
    "\n",
    "[('sentence', 0.19614946842193604), ('example', 0.18472394347190857), ('papers', 0.16767829656600952), ('though', 0.1488305777311325), ('length', 0.1437634527683258), ('relationship', 0.14222106337547302), ('students', 0.1338505744934082), ('evidence', 0.11947377026081085), ('one', 0.10210637748241425), ('representation', 0.09311568737030029)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Your Code From Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Dont't Change Code Here.\n",
    "def hash(astring):\n",
    "    return ord(astring[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "paragraph = 'Paragraphs are the building blocks of papers. Many students define paragraphs in terms of length: a paragraph is a group of at least five sentences, a paragraph is half a page long, etc. In reality, though, the unity and coherence of ideas among sentences is what constitutes a paragraph. A paragraph is defined as \"a group of sentences or a single sentence that forms a unit\" (Lunsford and Connors 116). Length and appearance do not determine whether a section in a paper is a paragraph. For instance, in some styles of writing, particularly journalistic styles, a paragraph can be just one sentence long. Ultimately, a paragraph is a sentence or group of sentences that support one main idea. In this handout, we will refer to this as the controlling idea, because it controls what happens in the rest of the paragraph. Paragraph development progresses with the expression of some type of support or evidence for the idea and the explanation that came before it. The example serves as a sign or representation of the relationship established in the idea and explanation portions of the paragraph.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = re.sub(r'\\[[0-9]*\\]', ' ', paragraph)\n",
    "paragraph = re.sub(r'\\s+', ' ', paragraph)          #to remove white spaces\n",
    "\n",
    "paragraph=paragraph.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentence Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paragraph = sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Word Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paragraph = [word_tokenize(sentence) for sentence in paragraph] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(paragraph)):\n",
    "    paragraph[i] = [word for word in paragraph[i] if word not in stopwords.words('english')]\n",
    "    paragraph[i] = [word for word in paragraph[i] if word not in string.punctuation]\n",
    "    paragraph[i] = [word for word in paragraph[i] if word!='``' and word!=\"''\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(paragraph, min_count = 1,workers=1,hashfxn=hash)\n",
    "words = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portions\n"
     ]
    }
   ],
   "source": [
    "word=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('progresses', 0.999999463558197), ('papers', 0.9999991655349731), ('page', 0.9999990463256836), ('particularly', 0.9999986886978149), ('paper', 0.9999986290931702), ('paragraph', 0.9999985098838806), ('paragraphs', 0.9999975562095642), ('representation', 0.25419333577156067), ('rest', 0.2517314851284027), ('refer', 0.25123676657676697)]\n"
     ]
    }
   ],
   "source": [
    "similar = model.wv.most_similar(word)\n",
    "print(similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
