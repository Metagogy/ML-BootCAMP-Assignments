{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "detected-pepper",
   "metadata": {},
   "source": [
    "### Question : \n",
    "Load the inbuilt bostan  dataset , Split the data into train and test . Build, compile, train and evaluate the model using adam optimizer, loss as \"amse\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-creation",
   "metadata": {},
   "source": [
    "### Description: \n",
    "Load the bostan dataset using inbuilt dataset function and split into train and test.\n",
    "\n",
    "Take only first column in independent variable and first column in dependent(labels) variable\n",
    "\n",
    "Do the standardscaler to the train and test data\n",
    "\n",
    "Build the bostan dataset model by using a sequential layer and add the 2 layers and first two activation functions as Relu \n",
    "layers having 64 neurons in each dense layer and last layer having activation function as relu layer with 1 neuron.\n",
    "\n",
    "Compile the model using adam optimizer, loss as \"amse\" and train the model using 5 epochs,1 as batch size.\n",
    "Evaluate the  model by using a test and predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-determination",
   "metadata": {},
   "source": [
    "### Level: \n",
    "Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-polls",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "Compile defines the loss function, the optimizer and the metrics.\n",
    "\n",
    "fit() is used for training models.\n",
    "\n",
    "evaluate function predicts the output for the given input and then computes the metric\n",
    "\n",
    "Library: [tf.keras/tensorflow]\n",
    "\n",
    "Category: ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-watch",
   "metadata": {},
   "source": [
    "### Input format : \n",
    "Dataset\n",
    "### Output format : \n",
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-wichita",
   "metadata": {},
   "source": [
    "### Sample input : \n",
    "Load the dataset using inbuilt function\n",
    "### Sample Output : \n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data=load_boston()\n",
    "\n",
    "data1_inde=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "\n",
    "data1_label=pd.DataFrame(data.target,columns=['target'])\n",
    "\n",
    "\n",
    "\n",
    "data1=pd.concat([data1_inde,data1_label],axis=1)\n",
    "\n",
    "x=data1.iloc[:,:13]\n",
    "\n",
    "y=data1.iloc[:,13]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "import keras\n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "#Sequential---Init the NN model\n",
    "from keras.models import Sequential\n",
    "#Dense --Normal Neural Network layer\n",
    "from keras.layers import Dense\n",
    "\n",
    "### Init the Neural Network Model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "### Add Input Layer\n",
    "\n",
    "x_train.shape[1]\n",
    "\n",
    "#add() of Sequential() is used to add layers\n",
    "#Dense\n",
    "\n",
    "model.add(Dense(input_dim=x_train.shape[1],kernel_initializer=\"random_uniform\",activation=\"relu\",units=20))\n",
    "\n",
    "### Add Hidden Layer\n",
    "\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"relu\",units=15))\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"relu\",units=15))\n",
    "\n",
    "### Add Output Layer\n",
    "\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"linear\",units=1))\n",
    "\n",
    "### Compile the Model\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",optimizer=\"adam\",metrics=[\"mean_absolute_percentage_error\"])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=10,epochs=50,verbose=0);\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\n",
    "ypred=model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2s=r2_score(y_test,ypred)\n",
    "\n",
    "r2s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greater-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 34) (116, 34) (235,) (116,)\n",
      "Test Accuracy: 0.888\n",
      "Predicted: 0.998\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "df = read_csv(path, header=None)\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "# make a prediction\n",
    "#row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
