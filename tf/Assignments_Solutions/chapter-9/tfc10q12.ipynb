{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : \n",
    "\n",
    "Load, Split, normalize and flatten the mnist dataset. Build, compile, train and evaluate the model using adam optimizer, loss as \"categorical_crossentropy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** : \n",
    "\n",
    "Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
    "\n",
    "Normalize the dataset images by dividing it with 255 of train and test images. \n",
    "\n",
    "Flatten the dataset images by using reshape. \n",
    "\n",
    "Build the mnist dataset model by using a sequential layer and adding first two activation functions as Relu layers having 64 \n",
    "\n",
    "neurons in each dense layer and last layer having activation function as Sigmoid layer with 10 neurons.\n",
    "\n",
    "Compile the model using adam optimizer, loss as \"categorical_crossentropy\" and train the model using 5 epochs, 32 as batch size.\n",
    "\n",
    "Evaluate the mnist model by using test images and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : \n",
    "\n",
    "Hard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation** :\n",
    "\n",
    "Compile defines the loss function, the optimizer and the metrics.\n",
    "\n",
    "fit() is used for training models.\n",
    "\n",
    "evaluate function predicts the output for the given input and then computes the metric\n",
    "\n",
    "**Library** : [tf.keras/tensorflow]\n",
    "\n",
    "**Category** : ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** : \n",
    "\n",
    "Dataset\n",
    "\n",
    "**Output format** : \n",
    "\n",
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample input** : \n",
    "\n",
    "Load the dataset using inbuilt function\n",
    "\n",
    "**Sample Output** : \n",
    "\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten the images.\n",
    "x_train.shape\n",
    "\n",
    "x_train=x_train.reshape(60000,784)\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "x_test.shape\n",
    "\n",
    "x_test=x_test.reshape(10000,784)\n",
    "\n",
    "x_test.shape\n",
    "\n",
    "# Scaling or Normilization\n",
    "\n",
    "#converts pixel values into 0 to 1\n",
    "x_train=keras.utils.normalize(x_train)\n",
    "x_test=keras.utils.normalize(x_test)\n",
    "\n",
    "y_train\n",
    "\n",
    "# One hot encoder\n",
    "\n",
    "#converts pixel values into 0 to 1\n",
    "y_train=keras.utils.to_categorical(y_train)\n",
    "\n",
    "#0 0 0 0 0 1 0 0 0 0\n",
    "y_train\n",
    "\n",
    "# Building the Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Init the NN Model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "# Add Input Layer\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "model.add(Dense(input_dim=784,kernel_initializer=\"random_uniform\",activation=\"relu\",units=200))\n",
    "\n",
    "# Add Hidden Layer\n",
    "\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"relu\",units=200))\n",
    "\n",
    "# Add Output Layer\n",
    "\n",
    "model.add(Dense(kernel_initializer=\"random_uniform\",activation=\"softmax\",units=10))\n",
    "\n",
    "# Compile the Model\n",
    "\n",
    "\n",
    "#categorical_crossentropy is the error calculating strategy == -âˆ‘(ylog(p))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=15,batch_size=32)\n",
    "_, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "#_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train:',train_acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
