{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tfc19q9q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9QoGyD2SdU"
      },
      "source": [
        "**Question**: Load, Split and normalize the mnist dataset. Build, compile and train the model using rmsprop  optimizer, loss as \"binary_crossentropy\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN-9SEx12Sdf"
      },
      "source": [
        "**Description:**  \n",
        "* Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
        "\n",
        "\n",
        "* Normalize the dataset images by dividing it with 255 for train and test images. \n",
        "\n",
        "\n",
        "* Build the mnist dataset model by using a sequential API and adding the first LSTM layer with\n",
        "\n",
        " 128 neurons and relu activation with input shape as x_train.shape Second layer with dropout has 0.2 neurons\n",
        "\n",
        " and the last layer is dense with 10 neurons with softmax activation as output layer. \n",
        " \n",
        " \n",
        "* Compile the model using ‘rmsprop’ optimizer, loss as \"binary_crossentropy\" and train the model using 3 epochs and\n",
        "\n",
        " validation data has testing values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-fdQCuv2Sdg"
      },
      "source": [
        "# Start Your Code Here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEC9QLp2Sdh"
      },
      "source": [
        "# Import Libraries.\n",
        "import tensorflow as  tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        " \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrdi5Coe2Sdi",
        "outputId": "eea20eac-55d9-45db-c7bb-e26d302b1e50"
      },
      "source": [
        "# train test split\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        " "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV6M458O2Sdi"
      },
      "source": [
        "# normalize\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        " "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCE9IG-z2Sdj"
      },
      "source": [
        "#to categorical\n",
        "y_train=to_categorical(y_train,10)\n",
        "y_test=to_categorical(y_test,10)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM2WkFpT2Sdj"
      },
      "source": [
        "# build model\n",
        " \n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wgwl4152Sdk"
      },
      "source": [
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
        " "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urj24_UK2Sdk"
      },
      "source": [
        "# fit or train the model\n",
        "model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test),verbose=0);"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRLmATb2Sdl"
      },
      "source": [
        "# evaluate The model\n",
        "los,acc=model.evaluate(x_test,y_test,verbose=0);\n",
        " \n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiFW2l6w2Sdl",
        "outputId": "aade0a15-be4a-4f99-8688-d4532a164c89"
      },
      "source": [
        "# Print Accuracy\n",
        "print(acc)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9713000059127808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfjpJ5ap2Sdn"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}