{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tfc15q11q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy8Bg7mfnGKl"
      },
      "source": [
        "**Question**:  Read a image with the help of tensorflow and convert to array and apply convolution on it and  print the array shape.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U8I1gKInGKw"
      },
      "source": [
        "**Description:**\n",
        "* Enter the single input string,  path of image \n",
        "* Reed the image  with the help of keras and tensorflow .\n",
        "* Apply preprocessing.image, use load_img() function\n",
        "* Use image_to_array(), resize() function\n",
        "* Create Sequential model and apply Conv2D with filter as 3x3 and padding as same\n",
        "* Predict the model and print the array \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CBNIi94nGKx"
      },
      "source": [
        "**Input format:**  \n",
        "\n",
        "\n",
        "**Output format:**  ndarray\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2bXPIObnGKx"
      },
      "source": [
        "**Sample input:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Sample output:**\n",
        "\n",
        "\n",
        "[[ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
        "  -172.41309 ]\n",
        "\n",
        " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
        "  -172.41309 ]\n",
        "\n",
        " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
        "  -172.41309 ]\n",
        "\n",
        " ...\n",
        "\n",
        " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
        "  -172.41309 ]\n",
        "\n",
        " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
        "  -172.41309 ]\n",
        "\n",
        " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
        "  -172.41309 ]]\n",
        "\n",
        " \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QFTU8wxnGKy"
      },
      "source": [
        "**Hint1:** Use tensorflow,keras,preprocessing.image\n",
        "\n",
        "**Hint2:** Use load_img(), img_to_array() function\n",
        "\n",
        "**Hint3:** Use reshape, Conv2D  function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDtOo3ZgnGKy"
      },
      "source": [
        "# Start Your Code Here."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUAqd6ZgnGKz"
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Activation,Flatten\n",
        "from keras.layers import Conv2D\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUWSB-JFnGK0"
      },
      "source": [
        "path='apple_2.jpg'\n",
        "image = tf.keras.preprocessing.image.load_img(path)\n",
        "image=tf.keras.preprocessing.image.img_to_array(image)\n",
        "lst=list(image.shape)\n",
        "image=image.reshape((lst[0],lst[1],lst[2],1))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSi46kZhnGK1",
        "outputId": "1c6daf0d-dad4-4c36-b697-d11b93d76d68"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(1, (3, 3),padding='same',input_shape=image.shape))\n",
        "model.add(Flatten())\n",
        "x=model.predict(image)\n",
        "print(x)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 250, 250, 3, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 250, 250, 3, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 250, 3, 1, 1).\n",
            "[[ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
            "  -172.41309 ]\n",
            " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
            "  -172.41309 ]\n",
            " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
            "  -172.41309 ]\n",
            " ...\n",
            " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
            "  -172.41309 ]\n",
            " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
            "  -172.41309 ]\n",
            " [ 117.26743   -28.290005 -172.41309  ...  117.26743   -28.290005\n",
            "  -172.41309 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzN0Bdu2nGK2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}