{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Build and Compile the mnist dataset with regularization l1 using RMSprop optimizer and loss as \"Sparse_categorical_crossentropy\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** : \n",
    "\n",
    "Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
    "\n",
    "Normalize the dataset images by dividing it with 255 for train and test images. \n",
    "\n",
    "Build the mnist dataset model by defining the function as get_regularised_model(wd,rate) using a sequential layer \n",
    "\n",
    "    1. Add the first Dense layer with 128 neurons having kernel regularizer as l1 and relu activation with input shape as x_train. \n",
    "\n",
    "    2. Second layer with dropout  called the argument as step. \n",
    "\n",
    "    3. The third layer has a Dense layer with 128 neurons and relu activation function and the fourth layer with dropout called the argument as step.\n",
    " \n",
    "    4. Repeat the third and fourth layer as 2 times \n",
    "\n",
    "    5. Add the next Dense layer with 64 neurons and tanh activation function and the next layer with dropout called the argument as step. \n",
    "\n",
    "    6. Repeat the above step with 32 neurons and activation function as softmax\n",
    "\n",
    "    7. Add last layer has dense with 1 neurons\n",
    "\n",
    "Call the function with momentum as 0.5 and value as 1e-5\n",
    "\n",
    "Compile the model using ‘RMSprop’ optimizer, loss as \"Sparse_categorical_crossentropy\" and metrics as Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** : Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format** : Neural network Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample input** : Load the dataset using inbuilt function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : Model compiling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(x_train.shape)\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def get_regularised_model(wd,rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l1(wd),activation = 'relu',input_shape=(x_train.shape[1],)),\n",
    "        tf.keras.layers.Dropout(rate),\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l1(wd), activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate),\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l1(wd), activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate),\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l1(wd), activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate),\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l1(wd), activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate),\n",
    "        tf.keras.layers.Dense(128, kernel_regularizer=regularizers.l1(wd), activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate),\n",
    "        tf.keras.layers.Dense(1)\n",
    "        \n",
    "    ])\n",
    "    return model\n",
    "model = get_regularised_model(1e-5, 0.5)\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer='RMSprop',\n",
    "             metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
