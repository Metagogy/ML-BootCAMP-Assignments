{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Read a sentence as input, apply Word tokenize and wordnet lemmatizer, and print the result to the console.\n",
    "\n",
    "Note : Use library as \n",
    " \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** :  Convert given text into tokens then apply wordnet lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format** : Before and after lemmatizing of each strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input** : \n",
    "    \n",
    "NLTK is a suite of libraries and programs for symbolic and statistical natural language processing for English \n",
    "\n",
    "written in the Python programming language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : \n",
    "    \n",
    "Actual: NLTK | Lemma: NLTK\n",
    "        \n",
    "Actual: is | Lemma: is\n",
    "        \n",
    "Actual: a | Lemma: a\n",
    "        \n",
    "Actual: suite | Lemma: suite\n",
    "        \n",
    "Actual: of | Lemma: of\n",
    "        \n",
    "Actual: libraries | Lemma: library\n",
    "        \n",
    "Actual: and | Lemma: and\n",
    "        \n",
    "Actual: programs | Lemma: program\n",
    "        \n",
    "Actual: for | Lemma: for\n",
    "        \n",
    "Actual: symbolic | Lemma: symbolic\n",
    "        \n",
    "Actual: and | Lemma: and\n",
    "        \n",
    "Actual: statistical | Lemma: statistical\n",
    "        \n",
    "Actual: natural | Lemma: natural\n",
    "        \n",
    "Actual: language | Lemma: language\n",
    "        \n",
    "Actual: processing | Lemma: processing\n",
    "        \n",
    "Actual: for | Lemma: for\n",
    "        \n",
    "Actual: English | Lemma: English\n",
    "        \n",
    "Actual: written | Lemma: written\n",
    "        \n",
    "Actual: in | Lemma: in\n",
    "        \n",
    "Actual: the | Lemma: the\n",
    "        \n",
    "Actual: Python | Lemma: Python\n",
    "        \n",
    "Actual: programming | Lemma: programming\n",
    "        \n",
    "Actual: language | Lemma: language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: NLTK | Lemma: NLTK\n",
      "Actual: is | Lemma: is\n",
      "Actual: a | Lemma: a\n",
      "Actual: suite | Lemma: suite\n",
      "Actual: of | Lemma: of\n",
      "Actual: libraries | Lemma: library\n",
      "Actual: and | Lemma: and\n",
      "Actual: programs | Lemma: program\n",
      "Actual: for | Lemma: for\n",
      "Actual: symbolic | Lemma: symbolic\n",
      "Actual: and | Lemma: and\n",
      "Actual: statistical | Lemma: statistical\n",
      "Actual: natural | Lemma: natural\n",
      "Actual: language | Lemma: language\n",
      "Actual: processing | Lemma: processing\n",
      "Actual: for | Lemma: for\n",
      "Actual: English | Lemma: English\n",
      "Actual: written | Lemma: written\n",
      "Actual: in | Lemma: in\n",
      "Actual: the | Lemma: the\n",
      "Actual: Python | Lemma: Python\n",
      "Actual: programming | Lemma: programming\n",
      "Actual: language | Lemma: language\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"\"\"NLTK is a suite of libraries and programs for symbolic and statistical \n",
    "            natural language processing for English written in the Python programming language\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "for i in tokens:\n",
    "       print(\"Actual: %s | Lemma: %s\"  % (i,lemmatizer.lemmatize(i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
