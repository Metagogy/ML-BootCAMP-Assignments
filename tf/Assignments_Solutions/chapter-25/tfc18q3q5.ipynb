{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Build, compile, train and evaluate chest X-Ray dataset using transfer learning (ResNet50) and data augmentation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Description**:\n",
    "\n",
    "Load the chest X-Ray training and testing datasets in respective paths \n",
    "\n",
    "The data set already splitted into 80:20 ratio\n",
    "\n",
    "Get the pre-trained resnet50 model and freeze initial layers.\n",
    "\n",
    "For fully connected layers use 512 neurons and 2 neurons in the last layer having relu and softmax activation functions respectively\n",
    "\n",
    "Using Image data generators preprocess train and testing sets by including augmentation in training data generator. Make sure to use (256,256) as image size or shape\n",
    "\n",
    "Compile the model with loss as binary cross-entropy and optimizer as stochastic gradient descent\n",
    "\n",
    "Train the model with 5 epochs, 32 as a batch size\n",
    "\n",
    "Finally, evaluate the model and print the validation accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Level**: Hard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format**: Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format**: Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input**: X-Ray dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output**: Accuracy: 0.656108617\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "# set to where the 'x-ray' directory is located\n",
    "data_dir = '/home/metagogy/x-ray data'\n",
    "\n",
    "# Training data dir\n",
    "training_dir = '/home/metagogy/x-ray data/Train'\n",
    "\n",
    "# Test data dir\n",
    "testing_dir = '/home/metagogy/x-ray data/Test'\n",
    "\n",
    "# number of classes \n",
    "num_classes = 2\n",
    "\n",
    "def get_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False \n",
    "    base_model_ouput = base_model.output\n",
    "    x = GlobalAveragePooling2D()(base_model_ouput)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "model = get_model()\n",
    "\n",
    "# Using ImageDataGenerator for pre-processing\n",
    "\n",
    "image_size = 256\n",
    "batch_size = 32\n",
    "\n",
    "# training data\n",
    "train_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "# validation data \n",
    "valid_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# create data generator objects\n",
    "train_generator = train_data_gen.flow_from_directory(training_dir, (image_size,image_size), batch_size=batch_size, class_mode='binary')\n",
    "valid_generator = valid_data_gen.flow_from_directory(testing_dir, (image_size,image_size), batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "# compile \n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# training\n",
    "model.fit_generator( \n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n//batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1)\n",
    "\n",
    "results = model.evaluate_generator(valid_generator)\n",
    "print(results[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
