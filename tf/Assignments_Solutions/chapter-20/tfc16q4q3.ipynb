{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Build and  compile flowers dataset using transfer learning (resnet50) by freezing top 140 layers without using data augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Description**:\n",
    "\n",
    "Load the flowers training and testing datasets in respective paths \n",
    "\n",
    "The data set already splitted into 80:20 ratio\n",
    "\n",
    "Using Image data generators preprocess train and testing sets. Make sure to use (224,224) as image size or shape\n",
    "\n",
    "Get the pre-trained resnet50 model and freeze the first 140 layers.\n",
    "\n",
    "For fully connected layers use 512 neurons and 5 neurons in the last layer having relu and softmax activation functions respectively\n",
    "\n",
    "Compile the model with loss as categorical cross-entropy and optimizer as stochastic gradient descent where learning rate is 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level**: Medium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format**: Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format**: Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input**: Flowers dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output**: Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import glob   \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "# set to where the 'flowers' directory is located\n",
    "data_dir = '/home/metagogy/Downloads/flowers'\n",
    "\n",
    "# Training data dir\n",
    "training_dir = '/home/metagogy/Downloads/flowers/Train'\n",
    "\n",
    "# Test data dir\n",
    "testing_dir = '/home/metagogy/Downloads/flowers/Test'\n",
    "\n",
    "# Using ImageDataGenerator for pre-processing\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "# training data\n",
    "train_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# validation data \n",
    "valid_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# create data generator objects\n",
    "train_generator = train_data_gen.flow_from_directory(training_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = valid_data_gen.flow_from_directory(testing_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "num_classes = 5\n",
    "split_at = 140\n",
    "\n",
    "def get_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    for layer in base_model.layers[:split_at]: layer.trainable = False\n",
    "    for layer in base_model.layers[split_at:]: layer.trainable = True\n",
    "    base_model_ouput = base_model.output\n",
    "    x = GlobalAveragePooling2D()(base_model_ouput)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
