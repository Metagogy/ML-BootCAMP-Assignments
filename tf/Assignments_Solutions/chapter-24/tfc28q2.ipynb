{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Build, compile, train the sunspot dataset using the Bidirectional LSTM model and print the mean absolute error loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "\n",
    "* The dataset consists from 1749/01/01 to 2017/08/31 \n",
    "\n",
    "* Load the dataset using pandas \n",
    "\n",
    "* Split the dataset into training till 3000 rows and testing sets as remaining \n",
    "\n",
    "* By using helper function turn data into a window dataset\n",
    "\n",
    "* For inference, we just need to convert the data into multiple samples of predictor variables.\n",
    "\n",
    "* For input, we are converting the time series into samples of 60 (window_size). The first 59 data points of a sample will be used as the predictor variables while the last data point will be used as the target variable.\n",
    "\n",
    "* Build a sequential model where input layer is Conv1D with 60 filters, kernel size as 5, relu as activation. Add 2 layers of Bidirectional lstm layers with 60 neurons each. Add two dense layers where 30 and 10 neurons respectively. Finally, add lambda layer for scaling output to same range of values\n",
    "\n",
    "* Compile the model using Huber as loss, ‘mae’ as an optimizer, learning rate as 1e-5\n",
    "\n",
    "* Train the model using 15 epochs and batch size as 32\n",
    "\n",
    "* Display the absolute mean error loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset.\n",
    "\n",
    "df = pd.read_csv('/home/metagogy/Sunspots.csv', usecols=['Date', 'Monthly Mean Total Sunspot Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.array(list(df.index))\n",
    "sunspots = list(df['Monthly Mean Total Sunspot Number'])\n",
    "series = np.array(sunspots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test data.\n",
    "\n",
    "t_train = time[:3000]\n",
    "train = series[:3000]\n",
    "t_test = time[3000:]\n",
    "test = series[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60  \n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "forecast_period = 30  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowed_dataset function.\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)  \n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda i: i.batch(window_size))\n",
    "    s = s.map(lambda i: (i[:-1], i[-1:]))  \n",
    "    s = s.shuffle(shuffle_buffer)  \n",
    "    s = s.batch(batch_size).prefetch(1) \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_forecast function.\n",
    "\n",
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda w: w.batch(window_size))\n",
    "    s = s.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(s)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = windowed_dataset(train, window_size=window_size,batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build  model.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=60, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\",input_shape=[None, 1]), \n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, activation=\"tanh\", return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, activation=\"tanh\", return_sequences=False)),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(training,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model_forecast(model,series[..., np.newaxis],window_size, batch_size)[3000 - window_size + 1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = tf.keras.metrics.mean_absolute_error(test, forecast).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
