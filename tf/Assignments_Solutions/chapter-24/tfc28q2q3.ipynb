{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Load, split the sunspot dataset. By using the helper function turn data into a window dataset and convert the data into multiple samples of predictor variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "The dataset consists from 1749/01/01 to 2017/08/31 \n",
    "\n",
    "Load the dataset using pandas \n",
    "\n",
    "Split the dataset into training till 3000 rows and testing sets as remaining \n",
    "\n",
    "By using helper function turn data into a window dataset\n",
    "\n",
    "For inference, we just need to convert the data into multiple samples of predictor variables.\n",
    "\n",
    "For input, we are converting the time series into samples of 60 (window_size). The first 59 data points of a sample will be used as the predictor variables while the last data point will be used as the target variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Level** : Medium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format:**\n",
    "CSV Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format:**\n",
    "User-defined function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input** :\n",
    "Sunspot dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : \n",
    "Windowed dataset function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/home/meQuestionogy/Sunspots.csv', usecols=['Date', 'Monthly Mean Total Sunspot Number'])\n",
    "\n",
    "time = np.array(list(df.index))\n",
    "sunspots = list(df['Monthly Mean Total Sunspot Number'])\n",
    "series = np.array(sunspots)\n",
    "\n",
    "t_train = time[:3000]\n",
    "train = series[:3000]\n",
    "t_test = time[3000:]\n",
    "test = series[3000:]\n",
    "\n",
    "window_size = 60  \n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "forecast_period = 30  \n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)  \n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda i: i.batch(window_size))\n",
    "    s = s.map(lambda i: (i[:-1], i[-1:]))  \n",
    "    s = s.shuffle(shuffle_buffer)  \n",
    "    s = s.batch(batch_size).prefetch(1) \n",
    "    return s\n",
    "\n",
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda w: w.batch(window_size))\n",
    "    s = s.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(s)\n",
    "    return forecast\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
