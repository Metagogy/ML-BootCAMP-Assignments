{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "tfc15q12q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz1EKTNhoo2A"
      },
      "source": [
        "**Question**:  Read a image with the help of tensorflow and convert to array and apply convolution on it and BatchNormalization  print the array shape.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLW0-HFMoo2K"
      },
      "source": [
        "**Description:**\n",
        "* Enter the single input string,  path of image \n",
        "* Reed the image  with the help of keras and tensorflow .\n",
        "* Apply preprocessing.image, use load_img() function\n",
        "* Use image_to_array(), reshape function\n",
        "* Create Sequential model and apply Conv2D with filter as 3x3 and padding as same\n",
        "* Use BatchNormalization\n",
        "* Predict the model and print the array \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G8Dnm1Hoo2L"
      },
      "source": [
        "**Input format:**  \n",
        "\n",
        "\n",
        "**Output format:**  ndarray\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htq1PLVsoo2L"
      },
      "source": [
        "**Sample input:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Sample output:**\n",
        "\n",
        "\n",
        "[[184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
        "\n",
        " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
        "\n",
        " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
        "\n",
        " ...\n",
        "\n",
        " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
        "\n",
        " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
        " \n",
        " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]]\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyU4Nfleoo2M"
      },
      "source": [
        "**Hint1:** Use tensorflow,keras,preprocessing.image\n",
        "\n",
        "**Hint2:** Use load_img(), img_to_array() function\n",
        "\n",
        "**Hint3:** Use reshape, Conv2D  function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DplmudfJoo2N"
      },
      "source": [
        "# Start Your Code Here."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3iabUqOoo2N"
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Activation,Flatten\n",
        "from keras.layers import Conv2D, BatchNormalization\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_-TK1S1oo2O"
      },
      "source": [
        "path='orange_4.jpg'\n",
        "image = tf.keras.preprocessing.image.load_img(path)\n",
        "image=tf.keras.preprocessing.image.img_to_array(image)\n",
        "lst=list(image.shape)\n",
        "image=image.reshape((lst[0],lst[1],lst[2],1))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09I-S2t-oo2P",
        "outputId": "da76e144-cf1d-4023-f209-55a928695615"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(1, 3,padding='same',input_shape=image.shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "x=model.predict(image)\n",
        "print(x)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 600, 600, 3, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 600, 600, 3, 1), dtype=tf.float32, name='conv2d_2_input'), name='conv2d_2_input', description=\"created by layer 'conv2d_2_input'\"), but it was called on an input with incompatible shape (None, 600, 3, 1, 1).\n",
            "[[184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
            " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
            " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
            " ...\n",
            " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
            " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]\n",
            " [184.4051   125.873795  75.1719   ... 184.4051   125.873795  75.1719  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01p1iAqcoo2Q"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}