{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Build, compile, train, and evaluate cats vs dogs dataset using the sequential model and data augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "\n",
    "* Load the cats vs dogs training and testing datasets in respective paths \n",
    "\n",
    "* The data set already splitted into 2000 training and 1000 validation sets\n",
    "\n",
    "* Using Image data generators preprocess train and validation sets by including augmentation in training data generator. Make sure to use (224,224) as image size or shape\n",
    "\n",
    "* Build a sequential model with 2 layers as 32 neurons and 1 layer as 64 neurons with relu activation function. Flatten the images and use the sigmoid function in the last dense layer with a dropout as 0.5\n",
    "\n",
    "* Compile the model with loss as binary cross-entropy and optimizer as adam with learning rate 0.001\n",
    "\n",
    "* Train the model with 5 epochs, 20 as a batch size\n",
    "\n",
    "* Finally, evaluate the model and print the validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries.\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation\n",
    "from tensorflow.keras.layers import Flatten, Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for training and testing\n",
    "\n",
    "train_path = \"C:\\Users\\gupta\\Desktop\\datasets\\cats vs dogs\\train\"\n",
    "valid_path = \"C:\\Users\\gupta\\Desktop\\datasets\\cats vs dogs\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation.\n",
    " \n",
    "image_size = 224\n",
    "batch_size = 20\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.15,\n",
    "                                    height_shift_range=0.15,\n",
    "                                    shear_range=0.15,\n",
    "                                    zoom_range=0.15\n",
    "                                    ,horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(train_path, target_size=(image_size,image_size), \n",
    "                                                     batch_size=batch_size, class_mode='binary')\n",
    "valid_generator = valid_data_gen.flow_from_directory(valid_path, target_size=(image_size,image_size), \n",
    "                                                     batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(image_size, image_size, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit_generator(train_generator,steps_per_epoch = train_generator.n//batch_size,epochs=5,validation_steps=valid_generator.n//batch_size,validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate_generator(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
