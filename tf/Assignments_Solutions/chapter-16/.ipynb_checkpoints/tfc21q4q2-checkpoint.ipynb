{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Load , preprocess and Split the ‘c’ program dataset belonging to kernel ‘c’ code. Build the model using LSTM and GRU layer.  Print the summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** :\n",
    "\n",
    "Load ‘ C ‘ code and set the path where C files reside and use regex to filter .c files\n",
    "\n",
    "Only consider first top_n characters and discard the rest for memory and computational efficiency\n",
    "\n",
    "Convert characters to integers\n",
    "\n",
    "Divide data in input (X) and output (y)\n",
    "\n",
    "Create input and output using the created sequences it means x should have height, width and channels ( Time steps ) i.e MAX_SEQ_LENGTH = 50 , STEP  = 3  and VOCAB_SIZE     = len(chars)\n",
    "\n",
    "Build the model with Sequential API and add the first layer as LSTM with 128 neurons, input_shape=(MAX_SEQ_LENGTH, VOCAB_SIZE), return_sequences=True and add second layer has dropout layer as 0.1 and add third layer as GRU with 128 neurons and fourth layer as Dropout layer as  0.1 and add Output as dense layer with VOCAB_SIZE, and activation as softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** : \n",
    "set path where C files belongs to\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format** : \n",
    "Model summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample input** : \n",
    "Load the dataset using c programming dataset belonging to kernel ‘ c ‘  code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : \n",
    "Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "path = r\"/home/sentinal/Music/Folder/archive/CODES/Resources/DL-Code/DL-Code/Generate Automatic Programming Code/attachment_kernel_lyst7535/kernel/\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "file_names = os.listdir()\n",
    "print(file_names)\n",
    "\n",
    "# use regex to filter .c files\n",
    "import re\n",
    "c_names = \".*\\.c$\"\n",
    "\n",
    "c_files = list()\n",
    "\n",
    "for file in file_names:\n",
    "    if re.match(c_names, file):\n",
    "        c_files.append(file)\n",
    "\n",
    "print(c_files)\n",
    "\n",
    "# load all c code in a list\n",
    "full_code = list()\n",
    "for file in c_files:\n",
    "    code = open(file, \"r\", encoding='utf-8')\n",
    "    full_code.append(code.read())\n",
    "    code.close()\n",
    "\n",
    "print(full_code[20])\n",
    "\n",
    "# merge different c codes into one big c code\n",
    "text = \"\\n\".join(full_code)\n",
    "print(\"Total number of characters in entire code: {}\".format(len(text)))\n",
    "\n",
    "top_n = 400000\n",
    "text = text[:top_n]\n",
    "\n",
    "text\n",
    "\n",
    "# create character to index mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "indices_char\n",
    "print(\"Vocabulary size: {}\".format(len(chars)))\n",
    "\n",
    "# define length for each sequence\n",
    "MAX_SEQ_LENGTH = 50          \n",
    "STEP           = 3          \n",
    "VOCAB_SIZE     = len(chars) \n",
    "\n",
    "sentences  = []              # X\n",
    "next_chars = []              # y\n",
    "\n",
    "for i in range(0, len(text) - MAX_SEQ_LENGTH, STEP):\n",
    "    sentences.append(text[i: i + MAX_SEQ_LENGTH])\n",
    "    next_chars.append(text[i + MAX_SEQ_LENGTH])\n",
    "\n",
    "print('Number of training samples: {}'.format(len(sentences)))\n",
    "\n",
    "sentences\n",
    "\n",
    "# create X and y\n",
    "X = np.zeros((len(sentences), MAX_SEQ_LENGTH, VOCAB_SIZE), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), VOCAB_SIZE), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(MAX_SEQ_LENGTH, VOCAB_SIZE), return_sequences=True,))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.GRU(128))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(VOCAB_SIZE, activation = \"softmax\"))\n",
    "\n",
    "# check model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
