{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Load, split, preprocess, and build the LSTM model using the sunspot dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "The dataset consists from 1749/01/01 to 2017/08/31 \n",
    "\n",
    "Load the dataset using pandas \n",
    "\n",
    "Split the dataset into training till 3000 rows and testing sets as remaining \n",
    "\n",
    "By using helper function turn data into a window dataset\n",
    "\n",
    "For inference, we just need to convert the data into multiple samples of predictor variables.\n",
    "\n",
    "For input, we are converting the time series into samples of 60 (window_size). The first 59 data points of a sample will be used as the predictor variables while the last data point will be used as the target variable.\n",
    "\n",
    "Build a sequential model where input layer is Conv1D with 60 filters, kernel size as 5, relu as activation. Add 2 layers of lstm layers with 60 neurons each. Add two dense layers where 30 and 10 neurons respectively. Finally, add lambda layer for scaling output to same range of values\n",
    "\n",
    "Print total model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Level** : Medium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format:**\n",
    "Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format:**\n",
    "Model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input** :\n",
    "Sunspot dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : \n",
    "60591\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/home/meQuestionogy/Sunspots.csv', usecols=['Date', 'Monthly Mean Total Sunspot Number'])\n",
    "\n",
    "time = np.array(list(df.index))\n",
    "sunspots = list(df['Monthly Mean Total Sunspot Number'])\n",
    "series = np.array(sunspots)\n",
    "\n",
    "t_train = time[:3000]\n",
    "train = series[:3000]\n",
    "t_test = time[3000:]\n",
    "test = series[3000:]\n",
    "\n",
    "window_size = 60  \n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "forecast_period = 30  \n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=-1)  \n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda i: i.batch(window_size))\n",
    "    s = s.map(lambda i: (i[:-1], i[-1:]))  \n",
    "    s = s.shuffle(shuffle_buffer)  \n",
    "    s = s.batch(batch_size).prefetch(1) \n",
    "    return s\n",
    "\n",
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    s = tf.data.Dataset.from_tensor_slices(series)\n",
    "    s = s.window(window_size, shift=1, drop_remainder=True)  \n",
    "    s = s.flat_map(lambda w: w.batch(window_size))\n",
    "    s = s.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(s)\n",
    "    return forecast\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(51)\n",
    "np.random.seed(51)\n",
    "training = windowed_dataset(train, window_size=window_size,batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=60, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\",input_shape=[None, 1]), \n",
    "  tf.keras.layers.LSTM(60, activation=\"tanh\", return_sequences=True),\n",
    "  tf.keras.layers.LSTM(60, activation=\"tanh\", return_sequences=False),\n",
    "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x * 100)  \n",
    "])\n",
    "\n",
    "print(model.count_params())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
