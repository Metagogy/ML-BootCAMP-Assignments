{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** : Load , preprocess and Split the ‘c’ program dataset belonging to kernel ‘c’ code. Build, compile and train the model using LSTM and GRU layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** :\n",
    "\n",
    "* Load ‘ C ‘ code and set the path where C files reside and use regex to filter .c files\n",
    "\n",
    "* Only consider first top_n characters and discard the rest for memory and computational efficiency\n",
    "\n",
    "* Convert characters to integers\n",
    "\n",
    "* Divide data in input (X) and output (y)\n",
    "\n",
    "* Create input and output using the created sequences it means x should have height, width and channels ( Time steps ) i.e MAX_SEQ_LENGTH = 50 , STEP  = 3  and VOCAB_SIZE     = len(chars)\n",
    "\n",
    "* Build the model with Sequential API and add the first layer as LSTM with 128 neurons, input_shape=(MAX_SEQ_LENGTH, VOCAB_SIZE), return_sequences=True and add second layer has dropout layer as 0.1 and add third layer as GRU with 128 neurons and fourth layer as Dropout layer as  0.1 and add Output as dense layer with VOCAB_SIZE, and activation as softmax\n",
    "\n",
    "* Compile the model with loss as categorical_crossentropy , SGD as optimizer and metrics as Accuracy\n",
    "\n",
    "* Fit or Train the model with Epochs as 20 , training set and batch_size as 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/home/sentinal/Music/Folder/archive/CODES/Resources/DL-Code/DL-Code/Generate Automatic Programming Code/attachment_kernel_lyst7535/kernel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex to filter .c files\n",
    "import re\n",
    "c_names = \".*\\.c$\"\n",
    "\n",
    "c_files = list()\n",
    "\n",
    "for file in file_names:\n",
    "    if re.match(c_names, file):\n",
    "        c_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all c code in a list\n",
    "full_code = list()\n",
    "for file in c_files:\n",
    "    code = open(file, \"r\", encoding='utf-8')\n",
    "    full_code.append(code.read())\n",
    "    code.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge different c codes into one big c code\n",
    "text = \"\\n\".join(full_code)\n",
    "print(\"Total number of characters in entire code: {}\".format(len(text)))\n",
    "\n",
    "top_n = 400000\n",
    "text = text[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create character to index mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define length for each sequence\n",
    "MAX_SEQ_LENGTH = 50          \n",
    "STEP           = 3          \n",
    "VOCAB_SIZE     = len(chars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences  = []              # X\n",
    "next_chars = []              # y\n",
    "\n",
    "for i in range(0, len(text) - MAX_SEQ_LENGTH, STEP):\n",
    "    sentences.append(text[i: i + MAX_SEQ_LENGTH])\n",
    "    next_chars.append(text[i + MAX_SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "X = np.zeros((len(sentences), MAX_SEQ_LENGTH, VOCAB_SIZE), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), VOCAB_SIZE), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape=(MAX_SEQ_LENGTH, VOCAB_SIZE), return_sequences=True,))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.GRU(128))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(VOCAB_SIZE, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer='SGD', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=20,verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,acc=model.evaluate(X,y,verbose=0)\n",
    "\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
