{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Build, compile and train flowers dataset using transfer learning (Resnet50) and data augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "\n",
    "Load the flowers training and testing datasets in respective paths \n",
    "\n",
    "The data set already splitted into 80:20 ratio\n",
    "\n",
    "Get the pre-trained resnet50 model and freeze initial layers.\n",
    "\n",
    "For fully connected layers use 512 neurons and 5 neurons in the last layer having relu and softmax activation functions respectively\n",
    "\n",
    "Compile the model with loss as categorical cross-entropy and optimizer as stochastic gradient descent\n",
    "\n",
    "Using Image data generators preprocess train and testing sets by including augmentation in training data generator. Make sure to use (224,224) as image size or shape\n",
    "\n",
    "Train the model with 5 epochs, 64 as a batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level**: Hard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format**: Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format**: Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input**: Flowers dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output**: Accuracy: 0.8625298142433167\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import glob   \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "# set to where the 'flowers' directory is located\n",
    "data_dir = '/home/metagogy/Downloads/flowers'\n",
    "\n",
    "# Training data dir\n",
    "training_dir = '/home/metagogy/Downloads/flowers/Train'\n",
    "\n",
    "# Test data dir\n",
    "testing_dir = '/home/metagogy/Downloads/flowers/Test'\n",
    "\n",
    "# number of classes \n",
    "num_classes = 5\n",
    "\n",
    "def get_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False \n",
    "    base_model_ouput = base_model.output\n",
    "    x = GlobalAveragePooling2D()(base_model_ouput)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Get the model\n",
    "model = get_model()\n",
    "\n",
    "# compile \n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Using ImageDataGenerator for pre-processing\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "# training data\n",
    "train_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                    shear_range=0.2, zoom_range=0.2, \n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "# validation data \n",
    "valid_data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "# create data generator objects\n",
    "train_generator = train_data_gen.flow_from_directory(training_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\n",
    "valid_generator = valid_data_gen.flow_from_directory(testing_dir, (image_size,image_size), batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# training\n",
    "model.fit_generator( \n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n//batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
