{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Load, Split, normalize and flatten the mnist dataset. Build, compile, train and evaluate the model using SGD optimizer, loss as sparse_categorical_crossentropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description :** \n",
    "\n",
    "* Load the mnist dataset using inbuilt dataset function and split into training and testing images.\n",
    "\n",
    "* Normalize the dataset images by dividing it with 255 and subtract 0.5 of train and test images. \n",
    "\n",
    "* Flatten the dataset images by using reshape. \n",
    "\n",
    "* Build the mnist dataset model by using a sequential layer and adding the first dense layer with 64 neurons and relu activation. Second layer has 64 neurons with softmax activation and output layer as sigmoid activation with 10 neurons.\n",
    "\n",
    "* Compile the model using ‘sgd’ optimizer, loss as sparse_categorical_crossentropy and train the model using 10 epochs, 32 as batch size.\n",
    "\n",
    "* Evaluate the mnist model by using test images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries.\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "\n",
    "X_train = (X_train / 255) - 0.5\n",
    "X_test = (X_test / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images.\n",
    "\n",
    "X_train = X_train.reshape((-1, 784))\n",
    "X_test = X_test.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu' , input_shape=(784, )))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu' ))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "\n",
    "model.compile(optimizer='SGD', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "\n",
    "model.fit(X_train,y_train,epochs=10,batch_size=32,verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "\n",
    "score=model.evaluate(X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9567999839782715\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy.\n",
    "\n",
    "print(score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
