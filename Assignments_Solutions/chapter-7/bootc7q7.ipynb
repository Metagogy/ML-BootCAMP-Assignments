{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Build, compile, train and evaluate the Iris model using binary cross entropy as loss function and adam as optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** : \n",
    "\n",
    "* Load the iris.csv dataset and Drop “Id” variable(column) , axis = 1 \n",
    "\n",
    "* Split into training and testing with test size = 0.1 and random state = 0\n",
    "\n",
    "* Build the model by using Sequential model and adding first activation function as Relu layer having 8 neurons and next three activation functions as Relu layer having 10 neurons each and last activation function as Softmax layer has 3 neurons\n",
    "\n",
    "* Compile the model by using loss function as Binary cross entropy  and Optimizer as adam\n",
    "\n",
    "* Fit or Train the model by using 5 epochs and  2 as batch size \n",
    "\n",
    "* Evaluate the model by using test values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Level** : Hard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format** : \n",
    "    \n",
    "Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output format** : \n",
    "    \n",
    "Neural networks model accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Input** :\n",
    "    \n",
    "Load the iris.csv dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Output** : \n",
    "    \n",
    "Accuracy: 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_296 (Dense)            (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 563\n",
      "Trainable params: 563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "60/60 - 0s - loss: 1.0235 - accuracy: 0.4500\n",
      "Epoch 2/5\n",
      "60/60 - 0s - loss: 0.7583 - accuracy: 0.8083\n",
      "Epoch 3/5\n",
      "60/60 - 0s - loss: 0.5614 - accuracy: 0.7583\n",
      "Epoch 4/5\n",
      "60/60 - 0s - loss: 0.4270 - accuracy: 0.9083\n",
      "Epoch 5/5\n",
      "60/60 - 0s - loss: 0.3901 - accuracy: 0.8250\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001C204741430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3166 - accuracy: 0.9333\n",
      "Test score 0.31660982966423035\n",
      "Test accuracy 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "# tf.random.set_seed(1)\n",
    "# import random as rn\n",
    "# rn.seed(1)\n",
    "data = pd.read_csv ('Iris.csv')\n",
    "data = data.drop(['Id'], axis = 1)\n",
    "X = np.array(data.drop(['Species'] , axis = 1))\n",
    "Y = np.array(data['Species']).reshape(-1,1)\n",
    "\n",
    "onehot=OneHotEncoder(sparse=False)\n",
    "\n",
    "Y=onehot.fit_transform(Y)\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "input_dim = (4,)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(20, input_shape = input_dim , activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, epochs = 5, batch_size = 2,verbose=2)\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"Test score\",scores[0])\n",
    "print(\"Test accuracy\",scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model=load_model('Iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.3823 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3822830319404602, 0.9666666388511658]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# tf.random.set_seed(1)\n",
    "# import random as rn\n",
    "# rn.seed(1)\n",
    "data = pd.read_csv ('Iris.csv')\n",
    "data = data.drop(['Id'], axis = 1)\n",
    "X = np.array(data.drop(['Species'] , axis = 1))\n",
    "Y = np.array(data['Species']).reshape(-1,1)\n",
    "\n",
    "onehot=OneHotEncoder(sparse=False)\n",
    "\n",
    "Y=onehot.fit_transform(Y)\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "input_dim = (4,)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(20, input_shape = input_dim , activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, epochs = 5, batch_size = 2,verbose=2)\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"Test score\",scores[0])\n",
    "print(\"Test accuracy\",scores[1])\n",
    "\n",
    "\n",
    "model.save(\"Iris_model.h5\")\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model=load_model('Iris_model.h5')\n",
    "\n",
    "model.evaluate(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
